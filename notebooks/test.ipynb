{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56291f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37dea07",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Imitator' from partially initialized module 'src.mslm.models' (most likely due to a circular import) (/home/giorgio6846/Code/Sign-AI/Sign-Giorgio/src/mslm/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmslm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Imitator, PositionalEncoding\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmslm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KeypointDataset, SignDataLoader, collate_fn\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmslm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tools\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Sign-AI/Sign-Giorgio/src/mslm/models/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mearly_stopping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimitator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Imitator\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcomponents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PositionalEncoding\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Sign-AI/Sign-Giorgio/src/mslm/utils/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mearly_stopping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# from .llm_tools import Tools\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msetup_train\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfigLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Sign-AI/Sign-Giorgio/src/mslm/utils/setup_train.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, random_split\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#Imported Classes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmslm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Imitator\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmslm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmslm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KeypointDataset, collate_fn, GRPCDataset, BatchSampler\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Imitator' from partially initialized module 'src.mslm.models' (most likely due to a circular import) (/home/giorgio6846/Code/Sign-AI/Sign-Giorgio/src/mslm/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.mslm.models import Imitator, PositionalEncoding\n",
    "from src.mslm.dataloader import KeypointDataset, SignDataLoader, collate_fn\n",
    "from src.mslm.utils.llm_tools import Tools\n",
    "\n",
    "from src.mslm.inference import MultimodalSignLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59d2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParameters = {\n",
    "    \"input_size\": 543*2,\n",
    "    \"output_size\": 3072,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"epochs\": 1000,\n",
    "    \"logIntervals\": 20,\n",
    "    \"checkpointIntervals\": 40,\n",
    "    \"batchSize\": 32,\n",
    "    \"frameClips\": 15 * 35,\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"validation_ratio\": 0.2\n",
    "}\n",
    "# model = Imitator(input_size=modelParameters[\"input_size\"], T_size=modelParameters[\"frameClips\"], output_size=modelParameters[\"output_size\"]).to(modelParameters[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a90c520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pt\n"
     ]
    }
   ],
   "source": [
    "!ls ../../outputs/checkpoints/50/2/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be5450a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.serialization.add_safe_globals([Imitator, PositionalEncoding, FastLanguageModel, Tools])\n",
    "model_checkpoint_path = \"../../outputs/checkpoints/50/2/5/model.pt\"\n",
    "model_checkpoint_path = \"../../outputs/checkpoints/50/2/5/model.pt\"\n",
    "state_dict = torch.load(model_checkpoint_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "973395ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = os.path.join(os.path.dirname(os.getcwd()), os.pardir, \"data\", \"dataset2\")\n",
    "h5File = os.path.join(DataPath, \"keypoints.h5\")\n",
    "csvFile = os.path.join(DataPath, \"meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "798b57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048 * 2\n",
    "load_in_4bit = True\n",
    "dtype=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "493a9c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Ti. Num GPUs = 1. Max memory: 15.576 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "llama_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e445d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = llama_model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf14b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Ti. Num GPUs = 1. Max memory: 15.576 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "LOG = False\n",
    "tools = Tools()\n",
    "keypointReader = KeypointDataset(h5Path=h5File, labelsCSV=csvFile, max_seq_len=modelParameters[\"frameClips\"])[0]\n",
    "dataset = SignDataLoader(tokenizer, [keypointReader], modelParameters[\"device\"])\n",
    "test_dataloader = DataLoader(dataset, batch_size=modelParameters[\"batchSize\"], shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ff01e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = state_dict.to(modelParameters[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecb809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['_orig_mod.stgcn.blocks.0.spatial_conv.weight', '_orig_mod.stgcn.blocks.0.spatial_conv.bias', '_orig_mod.stgcn.blocks.0.temp_conv.weight', '_orig_mod.stgcn.blocks.0.temp_conv.bias', '_orig_mod.stgcn.blocks.0.norm.weight', '_orig_mod.stgcn.blocks.0.norm.bias', '_orig_mod.stgcn.blocks.0.norm.running_mean', '_orig_mod.stgcn.blocks.0.norm.running_var', '_orig_mod.stgcn.blocks.0.norm.num_batches_tracked', '_orig_mod.stgcn.blocks.1.spatial_conv.weight', '_orig_mod.stgcn.blocks.1.spatial_conv.bias', '_orig_mod.stgcn.blocks.1.temp_conv.weight', '_orig_mod.stgcn.blocks.1.temp_conv.bias', '_orig_mod.stgcn.blocks.1.norm.weight', '_orig_mod.stgcn.blocks.1.norm.bias', '_orig_mod.stgcn.blocks.1.norm.running_mean', '_orig_mod.stgcn.blocks.1.norm.running_var', '_orig_mod.stgcn.blocks.1.norm.num_batches_tracked', '_orig_mod.temporal_adjuster.0.weight', '_orig_mod.temporal_adjuster.0.bias', '_orig_mod.linear_out.weight', '_orig_mod.linear_out.bias'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a14d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acdfdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for k, v in state_dict.items():\n",
    "    new_key = k.replace('_orig_mod.', '')  # elimina el prefijo\n",
    "    new_state_dict[new_key] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9aee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model with state dict\n",
    "model = Imitator(input_size=modelParameters[\"input_size\"], T_size=modelParameters[\"frameClips\"], output_size=modelParameters[\"output_size\"]).to(modelParameters[\"device\"])\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6f62c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cerrar las canillas durante el cepillado de dientes, de lavarse las manos, de la cara, de afeitarse, de lavar los platos, pelar papas, en lugar de dejar correr el agua.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypointReader[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c80811e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128000,  24913,    277,   5252,    649,  34344,  30331,    658,  63190,\n",
       "           484,   2172,    409,    294,  27335,     11,    409,  30583,   2648,\n",
       "          5252,  97349,     11,    409,   1208,  48034,     11,    409,    264,\n",
       "         62221,   2648,     11,    409,  30583,    277,   2537,    628,  14357,\n",
       "            11,  12077,    277,  26365,    300,     11,    665,  35000,    409,\n",
       "         81499,   1867,  38149,    658,  56562,     13, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "        128004, 128004])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdd02f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90e46d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): Imitator(\n",
       "    (linear): Linear(in_features=1086, out_features=1024, bias=True)\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (temporal_adjuster): Sequential(\n",
       "      (0): Linear(in_features=525, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (linear_out): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db0a6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf6ea038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 07 Apr 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Enumera los pasos descritos:\n",
      "\n",
      " νεφώσεις νεφώσεις a aauseRal los chtě los de los, de de de de de ForCanBeConverted lakrvldkf de<|eot_id|>krvldkfkrvldkfkrvldkfkrvldkfkrvldkfkrvldkf);\n",
      "krvldkfkrvldkf);\n",
      "�krvldkf�\tTokenNameIdentifier����);\n",
      ");\n",
      "����������始化��始化����ючисьючись��������������������������ючись����������ючись��ючись�ıntı�����������������ючись������<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Parece que hay un texto incompleto o incomunicativo. ¿Podría proporcionar más contexto o aclarar qué pasos se refiere?<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "llama_model.eval()\n",
    "mslm = MultimodalSignLM(llama_model, tokenizer, \"cuda\")\n",
    "\n",
    "text = \"Enumera los pasos descritos:\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, embeds in test_dataloader:\n",
    "        data = data.to(modelParameters[\"device\"])\n",
    "        sign_embed = model(data).to(\"cuda\")\n",
    "        sign_embed = sign_embed.to(dtype=torch.bfloat16)\n",
    "\n",
    "        # Normaliza ambos embeddings antes de calcular similitud\n",
    "        sign_embed = sign_embed.to(\"cuda\")\n",
    "        embeds = embeds.to(\"cuda\")\n",
    "        \n",
    "        print(mslm.generate(sign_embed, text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
